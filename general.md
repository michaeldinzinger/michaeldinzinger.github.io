---
layout: general
table-content-length: tables/general-content-length.html
table-crawldelay: tables/general-crawldelay.html
table-num-lines: tables/general-num-lines.html
table-num-user-agents: tables/general-num-user-agents.html
table-num-sitemaps: tables/general-num-sitemaps.html
---

General
=======

This page presents basic statistics on the collected robots.txt files and their development over the years. The statistics were calculate over all parsed files and additionally aggregated for 16 website categories. We therefore employed the [Curlie](https://curlie.org/) top level label to categorize the host of the respective URL (Example: https://**cnn.com**/robots.txt -> News). Note that the human-curated, filtered Curlie directory contains less than one million of hosts and consequently, most robots.txt files remain unlabeled.