---
layout: general
table_content_length: tables/general_content_length.html
table_crawldelay: tables/general_crawldelay.html
table_num_lines: tables/general_num_lines.html
table_num_user_agents: tables/general_num_user_agents.html
table_num_sitemaps: tables/general_num_sitemaps.html
---

General
=======

This page presents basic statistics on the collected robots.txt files and their development over the years. The statistics were calculate over all parsed files and additionally aggregated for 16 website categories. We therefore employed the [Curlie](https://curlie.org/) top level label to categorize the host of the respective URL (Example: https://**cnn.com**/robots.txt -> News). Note that the human-curated, filtered Curlie directory contains less than one million of hosts and consequently, most robots.txt files remain unlabeled.