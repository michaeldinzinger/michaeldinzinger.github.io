<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Robots.txt study</title>

    <link rel="stylesheet" href="/assets/css/style.css?v=cad3eca05cd4fb04f6fcabb8a3c8ad91788f64df">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script src="/assets/js/jquery-3.6.0.min.js?v=cad3eca05cd4fb04f6fcabb8a3c8ad91788f64df"></script>
    <style>
      table.matrix tbody tr th {
        font-weight: bold;
      }
      table tbody th { font-weight: normal; }
      table tbody td { text-align: right; }
    </style>

  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Longitudinal study of robots.txt files</h1>
        <p>Different annual statistics of the Common Crawl robots.txt web archives
        </p>

        
          <nav>
            <p>
            
              <a href="/">Overview</a><br/>
            
              <a href="/file-statistics">File statistics</a><br/>
            
              <a href="/top-user-agents">Top user agents</a><br/>
            
              <a href="/user-agent-bias">User agent bias</a><br/>
            
              <a href="/resources">Resources</a><br/>
            
            </p>
          </nav>
        

        
          <p class="view"><a href="https://opencode.it4i.eu/openwebsearcheu-public/commoncrawl-parser">View the Software Project on GitLab</a></p>
        

      </header>
      <section>

      <h1 id="resources">Resources</h1>

<p>In the course of the study, we have extracted the URLs of the valid robots.txt files from the crawl dump in December 2023, as well as the Sitemap links from the robots.txt files. Moreover, the links are aggregated by website category using the Curlie top level labels. Both datasets are available for download on this <a href="https://zenodo.org/records/10511292">Zenodo Repository</a>.</p>


      
      <table border="2">
    <thead>
      <tr>
        <th colspan="3">Robots.txt URLs</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>List of all valid robots.txt URLs</td>
        <td>41,611,704</td>
        <td><a href="https://zenodo.org/api/records/10511292/draft/files/all-robotstxt.zip/content" download>Download</a></td>
      </tr>
      <tr>
        <td>Curlie-curated list of valid robots.txt URLs</td>
        <td>314,228</td>
        <td><a href="https://zenodo.org/api/records/10511292/draft/files/robotstxt-curlie.zip/content" download>Download</a></td>
      </tr>
    </tbody>
    <thead>
      <tr>
        <th colspan="3">Sitemap links</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>List of all sitemap links</td>
        <td>32,252,027</td>
        <td><a href="https://zenodo.org/api/records/10511292/draft/files/all-sitemaps.zip/content" download>Download</a></td>
      </tr>
      <tr>
        <td>Curlie-curated list of sitemap links</td>
        <td>254,298</td>
        <td><a href="https://zenodo.org/api/records/10511292/draft/files/sitemaps-curlie.zip/content" download>Download</a></td>
      </tr>
    </tbody>
</table>
      <br>
      

      </section>
      <footer>
        
        <p>This project is maintained by <a href="https://github.com/michaeldinzinger">michaeldinzinger</a></p>
        
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>

  </body>
</html>
<!--
 Based on:
  https://github.com/pages-themes/minimal
  https://github.com/orderedlist/minimal
  http://tablesorter.com/
-->