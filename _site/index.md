Annual statistics of Common Crawl robots.txt archives
=====================================================

Statistics of [Common Crawl](https://commoncrawl.org/)'s [web archives](https://commoncrawl.org/the-data/get-started/) on robots.txt files:

* [Overview](overview) - Number of parsed documents, Capture times, Distribution of HTTP status codes
* [Basic statistics](basic-statistics) - Average content length (file size), Average crawl delay, Average number of lines, user agents and sitemaps
* [Top user agents](top-user-agents) - most frequently used product tokens over the years
* [User agent bias](user-agent-bias) - Number of *disallow all* instructions per user agent over the years, Average number of `allow` and `disallow` instructions per user agent over the years; overall and per website category
* [Resources](resources) - Dataset of extracted sitemap links; overall and per website category
